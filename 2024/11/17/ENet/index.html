<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=" id=&quot;ENet&quot;&gt;&lt;a href=&quot;#ENet&quot; class=&quot;headerlink&quot; title=&quot;ENet&quot;&gt;&lt;/a&gt;ENet&lt;/h2&gt;&lt;p&gt;在本文中，我们提出了一种名为ENet（高效神经网络）的新型深度神经网络体系结构，专门针对要求低延迟操作的任务而创建。ENet速度提高了18倍，所需FLOP减少了75倍，参数减少了79倍，并提供了与现有模型相似或更高的精度。&lt;br&gt;&lt;img src=&quot;/./ENet/model.jpg&quot; alt=&quot;ENet模型框架&quot; title=&quot;ENet模型框架&quot;&gt;"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>0.4M超超小语义分割模型-ENet | Welcome to Wwj's blog</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 7.1.1"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a></nav><div class="container post-meta"><div class="post-time">2024-11-17</div></div></div><div class="container post-header"><h1>0.4M超超小语义分割模型-ENet</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#ENet"><span class="toc-number">1.</span> <span class="toc-text">ENet</span></a></li></ol></details></div><div class="container post-content"><h2 id="ENet"><a href="#ENet" class="headerlink" title="ENet"></a>ENet</h2><p>在本文中，我们提出了一种名为ENet（高效神经网络）的新型深度神经网络体系结构，专门针对要求低延迟操作的任务而创建。ENet速度提高了18倍，所需FLOP减少了75倍，参数减少了79倍，并提供了与现有模型相似或更高的精度。<br><img src="/./ENet/model.jpg" alt="ENet模型框架" title="ENet模型框架"></p>
<p>上表给出了ENet的网络架构。它分为好几个阶段，如表中的水平线和每个块名后面的第一数字。上表的输出大小是针对输入图像分辨率为 512*512的。采用ResNets的观点，将其描述为具有单个主分支和带有与之分离的卷积核的扩展，然后合并为逐个元素的加法。</p>
<p>每个块由三个卷积层组成：减小通道数目的1×1投影、主卷积层（上图b中的conv）和1×1扩展通道层。在所有卷积之间放置BN和PReLU。与原始论文一样，将它们称为bottleneck。如果bottleneck正在下采样，则会在主分支上添加一个最大池化层。此外，第一个1×1投影卷积将替换为2×2卷积，且两个步幅均为2。将用零填充，以匹配特征图的数量。conv可以是带有3×3卷积核的标准卷积、空洞卷积或完全卷积（也称为反卷积或分解跨步卷积，这个是啥还真不知道）。有时用不对称卷积代替它，即5×1和1×5卷积的序列。为了正则化，使用空间Dropout，bottleneck2.0之前为0.01，之后为0.1。</p>
<p>Initial模块是上图中的a。第一阶段是有5个bottleneck模块组成的，第二阶段和第三阶段有相同的架构，除了第三阶段最开始没有下采样。前三个阶段是编码器，后两个阶段算是解码器。</p>
<p>为了降低卷积核的调用和内存溢出（cuDNN会分解卷积和偏置的加法），投影卷积中没有偏置项。这个选择对准确率没有任何影响。卷积层和非线性变换层中间有一个BN层。在解码器部分，最大池化被max uppooling操作所取代，padding被空间卷积所取代。没有在最后一个上采样模块中使用池化索引，因为初始块在输入帧的3个通道上运行，而最终输出具有C个特征图（对象类的数量）。同样，出于性能原因，仅将全卷积作为网络的最后一个模块，仅此一项就占用了解码器处理时间的一大部分。</p>
</div></div><div class="post-main post-comment"></div></article><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcdn.net/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>