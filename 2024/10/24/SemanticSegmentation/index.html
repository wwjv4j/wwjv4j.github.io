<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="在计算机视觉领域，目前神经网络的应用主要有图像识别，目标定位和检测，语义分割。图像识别就是告诉你图像是什么，目标定位和加测告诉你图像中目标在哪里，语义分割则是告诉你图像中的每个像素都归属于哪些类别。目前语义分割广泛应用于医学图像与无人驾驶登领域。由于最近在写一个关于钢材中缺陷检测的项目，因此记录一下有关于语义分割的学习历程。"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>计算机视觉-语义分割 | Welcome to Wwj's blog</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 7.1.1"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a></nav><div class="container post-meta"><div class="post-time">2024-10-24</div></div></div><div class="container post-header"><h1>计算机视觉-语义分割</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#UNet"><span class="toc-number">1.</span> <span class="toc-text">UNet</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E9%87%87%E6%A0%B7"><span class="toc-number">1.0.1.</span> <span class="toc-text">下采样</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E9%87%87%E6%A0%B7"><span class="toc-number">1.0.2.</span> <span class="toc-text">上采样</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#segmentation-models-pytorch-SMP"><span class="toc-number">2.</span> <span class="toc-text">segmentation_models_pytorch(SMP)</span></a></li></ol></details></div><div class="container post-content"><p>在计算机视觉领域，目前神经网络的应用主要有图像识别，目标定位和检测，语义分割。图像识别就是告诉你图像是什么，目标定位和加测告诉你图像中目标在哪里，语义分割则是告诉你图像中的每个像素都归属于哪些类别。目前语义分割广泛应用于医学图像与无人驾驶登领域。由于最近在写一个关于钢材中缺陷检测的项目，因此记录一下有关于语义分割的学习历程。</p>
<h2 id="UNet"><a href="#UNet" class="headerlink" title="UNet"></a>UNet</h2><p>说到语义分割，那就不得不提最经典的算法UNet了。该算法最初是为医学图像分割设计的，由于想过确实很好，后面被用于各个领域如卫星图像切割，工业瑕疵检测等。该模型采用一个encoder-decoder结构，encoder通过卷积和池化操作进行下采样，逐步提取中图像深层次的信息，decoder通过反卷积或插值进行上采样，并通过与encoder提取的特征进行拼接，获得图像深层和浅层的信息，最终得到原图像尺寸的分割结果。<br><img src="/./SemanticSegmentation/SegmentationUNetModel.png" alt="UNet模型框架" title="UNet模型框架"></p>
<h4 id="下采样"><a href="#下采样" class="headerlink" title="下采样"></a>下采样</h4><p>下采样的操作主要是对图像进行连续的卷积，池化操作来实现的，具体操作为</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">self.down1</span> = Down(base_c, base_c * <span class="number">2</span>)</span><br><span class="line"><span class="attr">self.down2</span> = Down(base_c * <span class="number">2</span>, base_c * <span class="number">4</span>)</span><br><span class="line"><span class="attr">self.down3</span> = Down(base_c * <span class="number">4</span>, base_c * <span class="number">8</span>)</span><br><span class="line"><span class="attr">self.down4</span> = Down(base_c * <span class="number">8</span>, base_c * <span class="number">16</span>)</span><br></pre></td></tr></table></figure>
<p>其中下采样层Down</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下采样模块：MaxPool2d 结合双卷积操作</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Down</span>(nn.<span class="title class_">Sequential</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"><span class="variable language_">self</span>, in_channels, out_channels</span>):</span><br><span class="line">        <span class="variable language_">super</span>(<span class="title class_">Down</span>, <span class="variable language_">self</span>).__init__(</span><br><span class="line">            nn.<span class="title class_">MaxPool2d</span>(<span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># 下采样</span></span><br><span class="line">            <span class="title class_">DoubleConv</span>(in_channels, out_channels)  <span class="comment"># 双卷积</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>MaxPool2d为池化层，步幅为2，经过池化层后，输出大小从(W，H)变为(W&#x2F;2，H&#x2F;2)<br>DoubleConv为双卷积层，该层通过两层卷积和批量归一化操作，提取出图像深一层的信息。</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 双卷积模块：基本单元，两个连续的卷积层，带有BatchNorm和ReLU激活</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">DoubleConv</span>(<span class="title">nn</span>.<span class="type">Sequential</span>):</span></span><br><span class="line"><span class="class">    def __init__(<span class="title">self</span>, <span class="title">in_channels</span>, <span class="title">out_channels</span>, <span class="title">mid_channels</span>=<span class="type">None</span>):</span></span><br><span class="line"><span class="class">        # mid_channels = out_channels / 4</span></span><br><span class="line"><span class="class">        if mid_channels is <span class="type">None</span>:</span></span><br><span class="line"><span class="class">            mid_channels = out_channels // 4</span></span><br><span class="line"><span class="class">        super(<span class="type">DoubleConv</span>, <span class="title">self</span>).__init__(</span></span><br><span class="line"><span class="class">            <span class="title">nn</span>.<span class="type">Conv2d</span>(<span class="title">in_channels</span>, <span class="title">mid_channels</span>, <span class="title">kernel_size</span>=3, <span class="title">padding</span>=1, <span class="title">bias</span>=<span class="type">False</span>),</span></span><br><span class="line"><span class="class">            nn.<span class="type">BatchNorm2d</span>(<span class="title">mid_channels</span>),</span></span><br><span class="line"><span class="class">            nn.<span class="type">ReLU</span>(<span class="title">inplace</span>=<span class="type">True</span>),</span></span><br><span class="line"><span class="class">            nn.<span class="type">Conv2d</span>(<span class="title">mid_channels</span>, <span class="title">out_channels</span>, <span class="title">kernel_size</span>=3, <span class="title">padding</span>=1, <span class="title">bias</span>=<span class="type">False</span>),</span></span><br><span class="line"><span class="class">            nn.<span class="type">BatchNorm2d</span>(<span class="title">out_channels</span>),</span></span><br><span class="line"><span class="class">            nn.<span class="type">ReLU</span>(<span class="title">inplace</span>=<span class="type">True</span>)</span></span><br><span class="line"><span class="class">        )</span></span><br></pre></td></tr></table></figure>
<h4 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h4><p>上采样最关键的一步是如何在恢复图像尺寸的过程中，与下采样过程中得到的图像各层次特征结合起来。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">self.up1</span> = Up(base_c * <span class="number">16</span>, base_c * <span class="number">8</span> // factor, bilinear)</span><br><span class="line"><span class="attr">self.up2</span> = Up(base_c * <span class="number">8</span>, base_c * <span class="number">4</span> // factor, bilinear)</span><br><span class="line"><span class="attr">self.up3</span> = Up(base_c * <span class="number">4</span>, base_c * <span class="number">2</span> // factor, bilinear)</span><br><span class="line"><span class="attr">self.up4</span> = Up(base_c * <span class="number">2</span>, base_c, bilinear)</span><br></pre></td></tr></table></figure>
<p>通过设计Up层的前向传播函数，将下采样过程中提取的特征进行拼接。</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">Up</span>(<span class="title">nn</span>.<span class="type">Module</span>):</span></span><br><span class="line"><span class="class">    def __init__(<span class="title">self</span>, <span class="title">in_channels</span>, <span class="title">out_channels</span>, <span class="title">bilinear</span>=<span class="type">True</span>):</span></span><br><span class="line"><span class="class">        super(<span class="type">Up</span>, <span class="title">self</span>).__init__()</span></span><br><span class="line"><span class="class">        if bilinear:</span></span><br><span class="line"><span class="class">            self.up = nn.<span class="type">Upsample</span>(<span class="title">scale_factor</span>=2, <span class="title">mode</span>=&#x27;<span class="title">bilinear&#x27;</span>, <span class="title">align_corners</span>=<span class="type">True</span>)</span></span><br><span class="line"><span class="class">            self.conv = <span class="type">DoubleConv</span>(<span class="title">in_channels</span>, <span class="title">out_channels</span>, <span class="title">in_channels</span> // 2)</span></span><br><span class="line"><span class="class">        else:</span></span><br><span class="line"><span class="class">            self.up = nn.<span class="type">ConvTranspose2d</span>(<span class="title">in_channels</span>, <span class="title">in_channels</span> // 2, <span class="title">kernel_size</span>=2, <span class="title">stride</span>=2)</span></span><br><span class="line"><span class="class">            self.conv = <span class="type">DoubleConv</span>(<span class="title">in_channels</span>, <span class="title">out_channels</span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    def forward(<span class="title">self</span>, <span class="title">x1</span>: <span class="title">torch</span>.<span class="type">Tensor</span>, <span class="title">x2</span>: <span class="title">torch</span>.<span class="type">Tensor</span>) -&gt; torch.<span class="type">Tensor</span>:</span></span><br><span class="line"><span class="class">        # 上采样</span></span><br><span class="line"><span class="class">        x1 = self.up(<span class="title">x1</span>)</span></span><br><span class="line"><span class="class">        </span></span><br><span class="line"><span class="class">        # 计算空间尺寸差异并进行padding</span></span><br><span class="line"><span class="class">        diff_y = x2.size()[2] - x1.size()[2]</span></span><br><span class="line"><span class="class">        diff_x = x2.size()[3] - x1.size()[3]</span></span><br><span class="line"><span class="class">        x1 = <span class="type">F</span>.pad(<span class="title">x1</span>, [<span class="title">diff_x</span> // 2, <span class="title">diff_x</span> - <span class="title">diff_x</span> // 2,</span></span><br><span class="line"><span class="class">                        <span class="title">diff_y</span> // 2, <span class="title">diff_y</span> - <span class="title">diff_y</span> // 2])</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">        # 拼接x1和x2</span></span><br><span class="line"><span class="class">        x = torch.cat([<span class="title">x2</span>, <span class="title">x1</span>], <span class="title">dim</span>=1)</span></span><br><span class="line"><span class="class">        x = self.conv(<span class="title">x</span>)</span></span><br><span class="line"><span class="class">        return x</span></span><br></pre></td></tr></table></figure>
<p>在上采样过程中，有两种方法，一种是直接进行反卷积，另一种是进行插值。这里使用了bilinear双线性插值，这会增加模型的训练时间，但综合表现会更好。<br>同时在前向传播过程中，需要输入两个参数，一个是上采样过程中的图像，另一个是相对应的下采样过程中的图像。具体过程如下</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">x1</span> = self.in_conv(x)</span><br><span class="line"><span class="attr">x2</span> = self.down1(x1)</span><br><span class="line"><span class="attr">x3</span> = self.down2(x2)</span><br><span class="line"><span class="attr">x4</span> = self.down3(x3)</span><br><span class="line"><span class="attr">x5</span> = self.down4(x4)</span><br><span class="line"></span><br><span class="line"><span class="attr">x</span> = self.up1(x5, x4)</span><br><span class="line"><span class="attr">x</span> = self.up2(x, x3)</span><br><span class="line"><span class="attr">x</span> = self.up3(x, x2)</span><br><span class="line"><span class="attr">x</span> = self.up4(x, x1)</span><br></pre></td></tr></table></figure>
<p>UNet算是最经典的一个语义分割模型了，但在此次项目中，我主要是使用SMP进行模型的构建。</p>
<h2 id="segmentation-models-pytorch-SMP"><a href="#segmentation-models-pytorch-SMP" class="headerlink" title="segmentation_models_pytorch(SMP)"></a>segmentation_models_pytorch(SMP)</h2><p>segmentation_models_pytorch是一个基于PyTorch的图像分割神经网络集合，能够高效的搭建所需的神经网络。</p>
</div></div><div class="post-main post-comment"></div></article><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcdn.net/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>